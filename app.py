import streamlit as st
import pandas as pd
import re, os, base64
from difflib import SequenceMatcher

# --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤ App (‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß-‡∏Ç‡∏≤‡∏ß) ---
st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏£‡∏π‡∏ï‡∏£‡∏∞‡∏Å‡∏π‡∏• v6.8", layout="wide")

def get_b64(file):
    if os.path.exists(file):
        try:
            with open(file, "rb") as f:
                return base64.b64encode(f.read()).decode()
        except: return None
    return None

img_b64 = get_b64("teacher.jpeg")
placeholder_img = "https://cdn-icons-png.flaticon.com/512/3429/3429433.png"

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Sarabun:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Sarabun', sans-serif; background-color: #ffffff; }
    
    .main-header { background-color: #1b5e20; padding: 25px; border-radius: 15px 15px 0 0; text-align: center; color: white; border-bottom: 5px solid #4caf50; }
    
    .teacher-card { background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 0 0 15px 15px; padding: 30px; margin-bottom: 35px; display: flex; align-items: center; gap: 30px; box-shadow: 0 4px 10px rgba(0,0,0,0.05); }
    .teacher-img { width: 130px; height: 130px; border-radius: 50%; border: 5px solid #1b5e20; object-fit: cover; }
    
    .level-header { background-color: #e8f5e9; color: #1b5e20; padding: 15px 25px; border-left: 10px solid #1b5e20; border-radius: 5px; margin-top: 40px; font-weight: 700; font-size: 1.5rem; }
    
    /* ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≤‡∏ß ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÑ‡∏°‡πà‡∏´‡∏ô‡∏≤ */
    .stDataFrame div[data-testid="stTable"] { font-size: 1.1rem; background-color: #ffffff !important; }
    td, th { color: #000000 !important; font-weight: 400 !important; border: 1px solid #dee2e6 !important; }
    th { font-weight: 700 !important; background-color: #f1f3f1 !important; } 
    
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß‡πÅ‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏£‡∏π
img_src = f"data:image/jpeg;base64,{img_b64}" if img_b64 else placeholder_img
st.markdown(f"""
<div class="main-header"><h2 style="margin:0; color:white; font-weight:700;">üìã ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Padlet ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞</h2></div>
<div class="teacher-card">
    <img src="{img_src}" class="teacher-img">
    <div>
        <h1 style="margin:0; font-size: 2.5rem; color: #1b5e20; font-weight:700;">‡∏Ñ‡∏£‡∏π‡∏ï‡∏£‡∏∞‡∏Å‡∏π‡∏• ‡∏ö‡∏∏‡∏ç‡∏ä‡∏¥‡∏ï</h1>
        <p style="margin:0; font-size: 1.2rem; color: #333 !important;">‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠ 2 ‡∏Ñ‡∏≥ | ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡∏≤‡∏ß | ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏õ‡∏Å‡∏ï‡∏¥</p>
    </div>
</div>
""", unsafe_allow_html=True)

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠ (‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 2 ‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å) ---
def strict_clean_name(n, sid):
    if pd.isna(n) or str(n).strip() == "" or str(n).lower() == "nan": 
        return f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠ (‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà {sid})"
    
    n = re.sub('<[^<]+?>', '', str(n)).replace('\n', ' ').strip()
    
    # 1. ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠
    prefixes = ['‡πÄ‡∏î‡πá‡∏Å‡∏ä‡∏≤‡∏¢', '‡πÄ‡∏î‡πá‡∏Å‡∏´‡∏ç‡∏¥‡∏á', '‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß', '‡∏ô‡∏≤‡∏¢', '‡∏ô‡∏≤‡∏á', r'‡∏î\.‡∏ä\.', r'‡∏î\.‡∏ç\.', r'‡∏ô\.‡∏™\.', r'‡∏ô\.‡∏™', r'‡∏î\.‡∏ä', r'‡∏î\.‡∏ç', '‡∏ô‡∏™.', '‡∏î‡∏ä.', '‡∏î‡∏ç.']
    for p in prefixes: n = re.sub(f'^{p}', '', n).strip()
    
    # 2. ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏Ç‡∏¢‡∏∞ (‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï, ‡∏à‡∏≤‡∏Å, ‡πÄ‡∏•‡πà‡∏ô, ‡∏á‡∏≤‡∏ô)
    junk_words = ['‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï', '‡∏°‡∏µ', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏•‡πà‡∏ô', '‡∏á‡∏≤‡∏ô', '‡∏™‡πà‡∏á‡∏á‡∏≤‡∏ô']
    for j in junk_words:
        n = re.sub(f'^{j}', '', n).strip()
        n = re.sub(f' {j} ', ' ', n).strip()

    # 3. ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏¢‡∏≤‡∏¢ (‡∏Å‡∏•‡∏∏‡πà‡∏°, ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°, ‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà)
    n = re.split(r'‡∏Å‡∏•‡∏∏‡πà‡∏°|‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà|‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°|‡∏ä‡∏±‡πâ‡∏ô|‡∏°\.|‡πÄ‡∏•‡∏Ç|No\.|#|‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô|\(|\[', n, flags=re.IGNORECASE)[0]
    
    # 4. ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà ‡∏û‡∏¢‡∏±‡∏ç‡∏ä‡∏ô‡∏∞ ‡∏™‡∏£‡∏∞ ‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå
    n = re.sub(r'[0-9‡πê-‡πô]', '', n)
    n = re.sub(r'[^\u0E01-\u0E3A\u0E40-\u0E4E A-Za-z\s]', '', n)
    
    # 5. ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 2 ‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å (‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•)
    words = n.split()
    if len(words) >= 2:
        return f"{words[0]} {words[1]}"
    elif len(words) == 1:
        return words[0]
    return f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠ (‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà {sid})"

# --- 3. ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏Å‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á (Fuzzy Merge) ---
def merge_similar_names(data_list):
    best_names = {}
    for item in data_list:
        sid = item['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']
        name = item['‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•']
        if "‚ö†Ô∏è" in name: continue
        if sid not in best_names:
            best_names[sid] = name
        else:
            if SequenceMatcher(None, name, best_names[sid]).ratio() > 0.75:
                if len(name) > len(best_names[sid]): best_names[sid] = name
    for item in data_list:
        sid = item['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']
        if sid in best_names and "‚ö†Ô∏è" not in item['‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•']:
            item['‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•'] = best_names[sid]
    return data_list

# --- 4. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå ---
uploaded_files = st.file_uploader("üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Padlet (Excel/CSV)", type=["csv", "xlsx"], accept_multiple_files=True)

if uploaded_files:
    all_raw_data = []
    full_acts = [f"‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà 1.{i}" for i in range(1, 15)]

    for f in uploaded_files:
        try:
            df = pd.read_csv(f, encoding='utf-8-sig') if f.name.endswith('.csv') else pd.read_excel(f)
            lv_match = re.search(r'([3-6])', f.name)
            level = f"‡∏°.{lv_match.group(1)}" if lv_match else "‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ"
            col_group = next((c for c in df.columns if any(k in str(c) for k in ["‡∏Å‡∏•‡∏∏‡πà‡∏°", "Group"])), None)

            for _, row in df.iterrows():
                combined_text = " ".join(map(str, row.values))
                sid_match = re.search(r'(?:‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà|No\.|#)\s*(\d+)', combined_text)
                act_match = re.search(r'1\.(\d{1,2})', combined_text)
                
                if sid_match and act_match:
                    sid = int(sid_match.group(1))
                    
                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏°‡∏≤‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô
                    raw_grp = str(row[col_group]).strip() if col_group else ""
                    if raw_grp == "nan" or raw_grp == "":
                        group_display = f"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà {f.name.split('.')[0]}"
                    else:
                        group_display = raw_grp if "‡∏Å‡∏•‡∏∏‡πà‡∏°" in raw_grp else f"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà {raw_grp}"
                        group_display = group_display.replace("‡∏Å‡∏•‡∏∏‡πà‡∏°", "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà ").replace("‡∏ó‡∏µ‡πà ‡∏ó‡∏µ‡πà", "‡∏ó‡∏µ‡πà")

                    name_candidates = [row.get('Subject'), row.get('‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤'), row.get('Body')]
                    raw_name = next((str(x) for x in name_candidates if pd.notna(x) and str(x).strip() != ""), "")
                    
                    all_raw_data.append({
                        '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà': sid,
                        '‡∏£‡∏∞‡∏î‡∏±‡∏ö': level,
                        '‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•': strict_clean_name(raw_name, sid),
                        '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°': group_display,
                        '‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°': f"‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà 1.{act_match.group(1)}"
                    })
        except: continue

    if all_raw_data:
        final_data = merge_similar_names(all_raw_data)
        df_master = pd.DataFrame(final_data).drop_duplicates()
        
        for lv in sorted(df_master['‡∏£‡∏∞‡∏î‡∏±‡∏ö'].unique()):
            st.markdown(f'<div class="level-header">üìç ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô {lv}</div>', unsafe_allow_html=True)
            df_lv = df_master[df_master['‡∏£‡∏∞‡∏î‡∏±‡∏ö'] == lv]
            pivot = df_lv.pivot_table(index=['‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', '‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°'], columns='‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°', values='‡∏£‡∏∞‡∏î‡∏±‡∏ö', aggfunc='count').fillna(0).astype(int)
            for act in full_acts: 
                if act not in pivot.columns: pivot[act] = 0
            res = pivot[full_acts].copy()
            res['‡∏£‡∏ß‡∏°'] = res.sum(axis=1)
            res = res.reset_index()
            res['is_missing'] = res['‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•'].apply(lambda x: 1 if "‚ö†Ô∏è" in str(x) else 0)
            res = res.sort_values(by=['is_missing', '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà']).drop(columns=['is_missing'])

            # --- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏Ç‡∏≤‡∏ß ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏õ‡∏Å‡∏ï‡∏¥ ---
            st.dataframe(
                res.style.set_properties(**{
                    'background-color': '#ffffff',
                    'color': '#000000',
                    'text-align': 'center'
                })
                .set_properties(subset=['‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°'], **{'text-align': 'left'})
                .apply(lambda x: ['background-color: #fffafa; color: #d32f2f;' if "‚ö†Ô∏è" in str(x['‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•']) else 'background-color: #ffffff;' for _ in x], axis=1)
                .format({a: lambda x: '‚úî' if x >= 1 else '-' for a in full_acts}),
                use_container_width=True, hide_index=True
            )
            st.download_button(f"üì• ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ {lv}", res.to_csv(index=False).encode('utf-8-sig'), f"Summary_{lv}.csv")
